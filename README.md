# PEC3 - La hibridación según Manovich

**Alumna**: Laura Moreno    **Profesor**: Francisco Miguel Gea Megías

![Texto alternativo](https://miro.medium.com/v2/resize:fit:2400/1*5MApCaZNUDQDPf8GDEmTQA.jpeg) Copyright: Hasselblad H6D
## Introducción
**Lev Manovich** es un teórico y profesor, entre muchas otras nomenclaturas que se le atribuyen a su persona, especialista en **cultura digital** y los nuevos medios. Nacido en 1960, en Moscú, se especializó en más de 3 ramas en la universidad distintas: pintura, arquitectura, informática y semiótica (estudio de los signos). En 1982 se mudó a los Estados Unidos, dónde se comenzó a interesar en todo el ámbito digital y de la tecnología, y el efecto que tenían estos en la cultura.

Manovich ha publicado varios libros durante su trayectoria, siendo uno de ellos **"El Lenguaje de los nuevos medios"**, traducido en trece idiomas. Más adelante, publicó **"El Software Toma el Mando"**, objeto de muchos estudios universitarios. En estos últimos, Lev deja caer conceptos imprescindibles para poder entender mejor la cultura digital y su evolución. Uno de ellos es el término de ***hibridación***. 

La hibridación según Lev Manovich, y resumida y detallada por Ferran Adell, "*es un proceso de remediación que da una **fusión entre los elementos** que comparten las técnicas de software y las interfícies generando una **experiencia nueva** y coherente*" (Manovich, 2013). En otras palabras, se unifican técnicas que un principio eran cada una para cada medio. Sabiendo que existen unos medios (**texto, audio, vídeo, etc...**) que conviven juntos (esta sería la definición de la multimedia), en la hibridación, estos medios van más allá de convivir juntos, sinó que se fusionan, que es diferente a experimentar estos medios por separado. Para diferenciar mejor la multimedia de la hibridación, Manovich da dos ejemplos claros: **la página web (multimedia) y Youtube (hibridación)**. 
>"*En la página web que antes comentaba (la típica con el formato de los años 2000: un cuerpo de texto decorado con imágenes y con algunos elementos añadidos) la experiencia del usuario es fragmentada. **Si uno lee el texto, no puede ver a la vez el vídeo**, ni observar las imágenes. Cada elemento tiene su marco de visualización aislado del resto. En los medios híbridos -en cambio- **uno experimenta todos los elementos en conjunto**. Imaginemos un vídeo en Youtube con subtítulos, textos añadidos que complementan la visualización del vídeo dándonos más información (in situ)...*" (Manovich, 2013) 

Este término se entenderá mejor con estos ejemplos que presento a continuación.



## Re-descubriendo la hibridación: Meta Ray-Ban
![Texto alternativo](https://wwd.com/wp-content/uploads/2023/09/RBM_KVS_Camera_Suanglass_Capture_RGB_16-9.jpg) Copyright: Ray-Ban oficial.

Uno de los productos más nuevos del mercado son **las gafas Meta de Ray - Ban**, la famosa marca de lentes de sol y vista. Gracias a la tecnología ofrecida por META, la nueva empresa formada por las aplicaciones más usadas internacionalmente como Facebook, Instagram, WhatsApp..., se ha conseguido crear unas **gafas inteligentes**, que permiten **realizar fotografía, vídeo y escuchar música** a la persona que las lleve puestas.

En el caso de este ejemplo, es una hibridación que va más allá de unificar diferentes medios. Vemos como los **elementos mediáticos se fusionan, pero, además haciendo una conexión entre medios físicos y digitales**, los digitales siendo el metaverso (software). Además, esta sinergia de elementos en unas gafas de uso diario, permite acercarnos más a la visión de futuro que se prevé, dónde toda nuestra vida tendrá su espacio virtual. 

Según la teoría de Manovich, estas gafas están realizadas de una combinación de **"genes"**/medios. (palabra usada apor Manevich al comparar la hibridación con la genética de los humanos al reproducirnos). Tanto las gafas per se, como la aplicación que la acompaña, están hechas por medios fusionados con el objetivo de  ofrecer una experiencia nueva, **nunca vivida antes culturalmente**, aún siendo lo más parecido a las gafas de realidad virtual. Estas gafas están conectadas a una interfaz que permite su conexión al smartphone para poder desarrollar sus ventajas. Todo el contenido que recibe y emite este invento es digital, **tiene una codificación y una inteligencia artificial detrás**, creados por Meta. 

El cerebro de las gafas. Las Ray-Ban Meta smart glasses están dirigidas por un Qualcomm Snapdragon AR 1 Gen1, un procesador que precisamente es capaz de lidiar con las nuevas capturas, vídeos y el asistente de IA. Este producto es una muestra de hibridación a raíz del fenómeno de la softwareización.
Con un mismo software se puede grabar vídeo, transmitir en directo, realizar fotografías, escuchar música y acceder a un asistente virtual.
Un producto híbrido como este, permite y cito: “La combinación de técnicas previamente incompatibles entre los diferentes medios”.

Personalmente, veo estas gafas comparables con los móviles android o la web (www), en su momento, que han sido tan significativas y producientes de un cambio bastante drástico en el mundo de la tecnología, que podríamos decir que las gafas son también una plataforma de medios móviles. Al igual que los mencionados, el software que da vida a estas gafas, hibrída una serie de medios, permitiendo el control de audiovisual en diferentes modos y funciones.

Este producto híbrido define nuevos formatos de medios pero usa técnicas ya existentes de interacción e interfaz, ya que el sistema de estas gafas es muy similar al de un smartphone, y la aplicación que las acompaña no es nada nuevo. Pero el formato que se usa para integrar esta interfaz de software es totalmente distinto a lo que estamos acostumbrados a ver actualmente.

En este caso, no se crea ningún lenguaje, sinó que junta diferentes tipos de lenguaje, como el visual, el auditivo, etc.  Es una remezcla de medios.


## Re-descubriendo la hibridación: BeReal
![Texto alternativo](https://cloudfront-eu-central-1.images.arcpublishing.com/prisa/WE6UUOBZGBCNLIXYCKJXYB6MZ4.png)

Bereal es la aplicación de moda, que permite compartir con todo el mundo qué estás haciendo en ese momento justo y dónde. Esto es posible gracias a que la aplicación abre la cámara frontal y trasera y saca una foto. Actualmente, también ha añadido otro medio, el vídeo. Cuando se realizan estas dos fotografías, también se graba un “BTS”, behind the scenes, parecido al “live” de iPhone.

Estas fotos no se publicarán, técnicamente, cuando la gente lo decida. La app envía una notificación a todo el mundo, a la misma hora, y quién lo sube a tiempo, tiene derecho a hacer una foto extra a la hora que quiera. Decía técnicamente porque realmente se puede subir igualmente una fotografía, aunque sea tarde.

Asimismo, BeReal permite comentar y reaccionar a las fotografías de los demás, usando unas fotografías tuyas imitando a unos emojis en concreto.

Detrás de una aplicación hay un algoritmo que es el que permite que en todos los dispositivos registrados llegue la notificación para subir la imagen, o para que se guarde la fotografía sola en el calendario. La app también usa la geolocalización del dispositivo para localizar dónde se ha realizado la fotografía y así, en el apartado “discover”, poder descubrir “BeReals” de otras personas de tu alrededor que no conoces.

Esta aplicación es un híbrido de distintos medios: imagen, vídeo, geolocalización, calendario, acceso a notificaciones y sonido.

Bereal ofrece diferentes maneras de navegar e interaccionar con los medios como son las fotos. Nunca había existido una interfaz que permitiera realizar fotografías por delante y por detrás simultáneamente. Además, cuando se sube la fotografía, se reproduce, tras unos segundos, el vídeo de cómo se ha realizado la fotografía. Y, en el caso de que se haya enlazado con Spotify, suena la música que la persona estaba escuchando en el momento que se estaba realizando las fotografías. De esta forma, se ofrece una experiencia totalmente nueva, que tiene como base y ejemplo otras redes sociales, pero remezclando los medios de una forma original.

Esta aplicación híbrida también ha sido centro de muchas críticas. Muchas personas se quejan de la falta de privacidad que una aplicación como esta ofrece. Qué más queda por saber de alguien si con una fotografía podemos saber dónde está, qué está haciendo justo en ese momento, si está escuchando música y la hora a la que la realiza. 

Como se puede observar, a veces también los avances tecnológicos y la hibridación puede ser controversial y no siempre positivo. Igualmente, yo opino la aplicación, aunque sí que puede llegar a tener mucha información sobre nosotros, los demás no tienen por qué tenerla si ajustamos la privacidad de lo que compartimos.

## Conclusiones
Con estos ejemplos tan cercanos, podemos observar como han evolucionado los medios y las fusiones entre ellos. La mayoría de páginas web, interfaces de los 90's no se podía considerar como híbridos, pero, en la actualidad, casi todas las aplicaciones y páginas web lleva a cabo una hibridación de medios que permite ofrecer una experiencia más plena e integrada de los medios a los usuarios, mejorando así la accesibilidad y la UX. Estos dos ejemplos muestran dos estrategias distintas de hibridación que explica Lev Manovich en su libro "El Software Toma el Mando", las gafas Meta de Ray-Ban son una forma nueva de representar el mundo, mientras que con BeReal, es una hibridación que no inventa nada nuevo pero usa otras técnicas en la interfaz para llevar a cabo esa integración de los medios y poder asimilar todos al mismo tiempo, a diferencia de cualquier elemento multimedia, que solo nos permite disfrutar de cada medio de forma separada. 

